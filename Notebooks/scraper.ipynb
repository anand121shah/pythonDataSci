{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/as-bestinclass/pythonDataSci/blob/main/scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfpW4l8uHPo1",
        "outputId": "e4fd7150-a381-4a3b-cba9-3c2b2959979f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autoscraper\n",
            "  Downloading autoscraper-1.1.14-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autoscraper) (2.27.1)\n",
            "Collecting bs4 (from autoscraper)\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from autoscraper) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->autoscraper) (4.11.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autoscraper) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autoscraper) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->autoscraper) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autoscraper) (3.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->autoscraper) (2.4.1)\n",
            "Building wheels for collected packages: bs4\n",
            "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=19cd729f9aa1e5e86d6948d6bbf279002bb187f19c1b086215921713810fe872\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
            "Successfully built bs4\n",
            "Installing collected packages: bs4, autoscraper\n",
            "Successfully installed autoscraper-1.1.14 bs4-0.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install autoscraper"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autoscraper import AutoScraper\n",
        "import requests"
      ],
      "metadata": {
        "id": "Ko7Pj1fMHr5k"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urls = [\n",
        "    \"https://www.wikipedia.org\",\n",
        "    \"https://www.youtube.com\",\n",
        "    \"https://www.reddit.com\",\n",
        "    \"https://www.amazon.com\",\n",
        "    \"https://www.twitter.com\",\n",
        "    \"https://www.imdb.com\",\n",
        "    \"https://www.ebay.com\",\n",
        "    \"https://www.stackoverflow.com\",\n",
        "    \"https://www.github.com\",\n",
        "    \"https://www.nytimes.com\",\n",
        "    \"https://www.craigslist.org\",\n",
        "    \"https://www.weather.com\",\n",
        "    \"https://www.quora.com\",\n",
        "    \"https://www.udemy.com\",\n",
        "    \"https://www.w3schools.com\",\n",
        "    \"https://www.bbc.co.uk\",\n",
        "    \"https://www.target.com\",\n",
        "    \"https://www.alibaba.com\",\n",
        "    \"https://www.pinterest.com\",\n",
        "    \"https://www.nba.com\",\n",
        "    \"https://www.nationalgeographic.com\",\n",
        "    \"https://www.npr.org\",\n",
        "    \"https://www.macys.com\",\n",
        "    \"https://www.zillow.com\",\n",
        "    \"https://www.netflix.com\"\n",
        "]"
      ],
      "metadata": {
        "id": "UB9AnM4fLUuC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "for url in urls:\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        print(f\"Website {url} is accessible with response 200\")\n",
        "    else:\n",
        "        print(f\"Website {url} is not accessible or returned an error\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKebUBHQK873",
        "outputId": "f6fc176c-343b-451b-c7ca-1c41ee486acd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Website https://www.wikipedia.org is accessible with response 200\n",
            "Website https://www.youtube.com is accessible with response 200\n",
            "Website https://www.reddit.com is accessible with response 200\n",
            "Website https://www.amazon.com is not accessible or returned an error\n",
            "Website https://www.twitter.com is accessible with response 200\n",
            "Website https://www.imdb.com is not accessible or returned an error\n",
            "Website https://www.ebay.com is accessible with response 200\n",
            "Website https://www.stackoverflow.com is accessible with response 200\n",
            "Website https://www.github.com is accessible with response 200\n",
            "Website https://www.nytimes.com is accessible with response 200\n",
            "Website https://www.craigslist.org is accessible with response 200\n",
            "Website https://www.weather.com is accessible with response 200\n",
            "Website https://www.quora.com is accessible with response 200\n",
            "Website https://www.udemy.com is accessible with response 200\n",
            "Website https://www.w3schools.com is accessible with response 200\n",
            "Website https://www.bbc.co.uk is accessible with response 200\n",
            "Website https://www.target.com is accessible with response 200\n",
            "Website https://www.alibaba.com is accessible with response 200\n",
            "Website https://www.pinterest.com is accessible with response 200\n",
            "Website https://www.nba.com is accessible with response 200\n",
            "Website https://www.nationalgeographic.com is accessible with response 200\n",
            "Website https://www.npr.org is accessible with response 200\n",
            "Website https://www.macys.com is not accessible or returned an error\n",
            "Website https://www.zillow.com is not accessible or returned an error\n",
            "Website https://www.netflix.com is accessible with response 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cell = 'https://www.alibaba.com/product-detail/Custom-Lightsaber-Cnc-Machining-Metal-Lightsaber_60820662948.html?s=p'\n",
        "requests.get(cell)\n",
        "print(cell)\n",
        "want_lst = ['lightsaber']\n",
        "scraper = AutoScraper()\n",
        "result"
      ],
      "metadata": {
        "id": "iRiBrZcRHz6U"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "requests.get(cell)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWjRJAnWJLrx",
        "outputId": "3d26e67e-ae3c-4596-db0d-ab19abbf2f52"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cell)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0Qkhn2OMS0q",
        "outputId": "79b5654c-c018-489b-faf5-a721901533fd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.alibaba.com/product-detail/Custom-Lightsaber-Cnc-Machining-Metal-Lightsaber_60820662948.html?s=p\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "want_lst = ['lightsaber']"
      ],
      "metadata": {
        "id": "D3Gao0FrH_uT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scraper = AutoScraper()"
      ],
      "metadata": {
        "id": "X2YLwE75IfFx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = scraper.build(cell, want_lst)"
      ],
      "metadata": {
        "id": "fZMfJDWpIopJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38yCDSZAIx6S",
        "outputId": "d02b401e-7de1-4aca-8648-96ca023c8812"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wZmNARXQJwzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from autoscraper import AutoScraper\n",
        "\n",
        "\n",
        "\n",
        "# Define the URL and make a request\n",
        "url = 'https://www.alibaba.com/'\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Specify the data you want to scrape\n",
        "    want_lst = ['lightsaber']\n",
        "\n",
        "    # Create an instance of AutoScraper and provide a sample input\n",
        "    scraper = AutoScraper()\n",
        "    sample = response.text\n",
        "    scraper.build(sample, want_lst)\n",
        "\n",
        "    # Scrape the data from the webpage\n",
        "    result = scraper.get_result()\n",
        "\n",
        "    # Print the scraped data\n",
        "    print(result)\n",
        "else:\n",
        "    print(\"Website is not accessible or returned an error\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "6tJadJkBM3zW",
        "outputId": "6c4e1acb-849f-48fc-fc94-181863af4fc8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidSchema",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidSchema\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-08687bba5813>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mscraper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoScraper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mscraper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwant_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Scrape the data from the webpage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autoscraper/auto_scraper.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, url, wanted_list, wanted_dict, html, request_args, update, text_fuzz_ratio)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \"\"\"\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_soup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mresult_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autoscraper/auto_scraper.py\u001b[0m in \u001b[0;36m_get_soup\u001b[0;34m(cls, url, html, request_args)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lxml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munescape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autoscraper/auto_scraper.py\u001b[0m in \u001b[0;36m_fetch_html\u001b[0;34m(cls, url, request_args)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0muser_headers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"headers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         if res.encoding == \"ISO-8859-1\" and not \"ISO-8859-1\" in res.headers.get(\n\u001b[1;32m    107\u001b[0m             \u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \"\"\"\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    527\u001b[0m         }\n\u001b[1;32m    528\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;31m# Get the appropriate adapter to use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0madapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# Start time (approximately) of the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mget_adapter\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;31m# Nothing matches :-/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mInvalidSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No connection adapters were found for {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidSchema\u001b[0m: No connection adapters were found for '<!-- tangram:6616 begin-->\\n<!DOCTYPE html>\\n<html class=\"rwd\">\\n<head>\\n    <meta name=\"p:domain_verify\" content=\"a963ddcfade0c77aae3e33cd28f57243\"/>\\n    <meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no\"/>\\n    <meta name=\"google-translate-customization\" content=\"9de59014edaf3b99-22e1cf3b5ca21786-g00bb439a5e9e5f8f-f\"/>\\n    <meta name=\"data-spm\" content=\"a2700\"/>\\n    <title>Alibaba.com: Manufacturers, Suppliers, Exporters & Importers from the world\\'s largest online B2B marketplace</title>\\n    <meta name=\"keywords\" content=\"Manufacturers, Suppliers, Exporters, Importers, Products, Trade Leads, Supplier, Manufacturer, Exporter, Importer\"/>\\n    <meta name=\"description\" content=\"Find quality Manufacturers, Suppliers, Exporters, Importers, Buyers, Wholesalers, Products and Trade Leads from our award-winning International Trade Site. Import &amp; Export on alibaba.com\"/>\\n\\t\\t\\t\\t<meta http-equiv=\\'x-dns-prefetch-control\\' content=\\'on\\'>\\n\\t    <link rel=\\'dns-prefetch\\' href=\\'//s.alicdn.com\\'>\\n\\t\\t<link rel=\\'dns-prefetch\\' href=\\'//i.alicdn.com\\'>\\n\\t\\t<link rel=\\'dns-prefetch\\' href=\\'//b.alicdn.com\\'>\\n\\t\\t<link rel=\\'dns-prefetch\\' href=\\'//is.alicdn.com\\'>\\n\\t\\t<link rel=\\'dns-prefetch\\' href=\\'//g.alicdn.com\\'>\\n\\t\\t<link rel=\\'dns-prefetch\\' href=\\'//..."
          ]
        }
      ]
    }
  ]
}